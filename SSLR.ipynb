{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce2684f9",
   "metadata": {},
   "source": [
    "## Covariate-dependent learning framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99488f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchmetrics.functional import accuracy\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import io_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b223692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = 'BNA'\n",
    "# data_dir = 'D:/ShareFolder/BNA/Proc'\n",
    "# out_dir = 'D:/ShareFolder/BNA/Result'\n",
    "data_dir = '/media/shuoz/MyDrive/HCP/BNA/Proc'\n",
    "out_dir = '/media/shuoz/MyDrive/HCP/BNA/Results'\n",
    "\n",
    "\n",
    "# atlas = 'AICHA'\n",
    "# data_dir = 'D:/ShareFolder/AICHA_VolFC/Proc'\n",
    "# out_dir = 'D:/ShareFolder/AICHA_VolFC/Result'\n",
    "\n",
    "sessions = ['REST1', 'REST2']  \n",
    "\n",
    "runs = ['RL', 'LR']\n",
    "# connection_type = 'both'  # inter, intra, or both\n",
    "connection_type = 'intra'\n",
    "random_state = 144\n",
    "clf = 'SVC'\n",
    "\n",
    "info = dict()\n",
    "data = dict()\n",
    "\n",
    "session = 'REST1'\n",
    "run_ = 'LR'\n",
    "half = 'Left'\n",
    "\n",
    "info_fname = 'HCP_%s_half_brain_%s_%s.csv' % (atlas, session, run_)\n",
    "info[run_] = io_.read_table(os.path.join(data_dir, info_fname), index_col='ID')\n",
    "data[run_] = io_.load_half_brain(data_dir, atlas, session, run_, connection_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ebbd0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _base import _pick_half\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "x, y = _pick_half(data[run_])\n",
    "y = label_binarize(y, classes=[1, -1])\n",
    "# y = y.reshape((-1, 1))\n",
    "genders = info[run_]['gender'].values\n",
    "\n",
    "idx_male = np.where(genders==0)[0]\n",
    "idx_female = np.where(genders==1)[0]\n",
    "\n",
    "\n",
    "x = torch.from_numpy(x)\n",
    "x = x.float()\n",
    "y = torch.from_numpy(y)\n",
    "y = y.long()\n",
    "genders = torch.from_numpy(genders.reshape((-1, 1)))\n",
    "genders = genders.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33d27385",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(nn.Module):\n",
    "    def __init__(self, n_features, n_classes, l1_hparam=0.0, l2_hparam=1.0,):\n",
    "        super().__init__()\n",
    "        self.l1_hparam = l1_hparam\n",
    "        self.l2_hparam = l2_hparam\n",
    "        self.linear = nn.Linear(n_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pred = torch.sigmoid(self.linear(x))\n",
    "        return pred\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)  # Generate predictions\n",
    "        pred_loss = F.cross_entropy(out, labels)  # Calculate loss\n",
    "        \n",
    "        # L1 regularizer\n",
    "        if self.l1_hparam > 0:\n",
    "            l1_reg = sum(param.abs().sum() for param in self.parameters())\n",
    "            loss += self.l1_hparam * l1_reg\n",
    "\n",
    "        # L2 regularizer\n",
    "        if self.l2_hparam > 0:\n",
    "            l2_reg = sum(param.pow(2).sum() for param in self.parameters())\n",
    "            loss += self.l2_hparam * l2_reg\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)  # Calculate loss\n",
    "        acc = accuracy(out, labels)  # Calculate accuracy\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()  # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()  # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "\n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93000aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_hparam = 0.0\n",
    "l2_hparam = 1.0\n",
    "\n",
    "\n",
    "# L1 regularizer\n",
    "# if l1_hparam > 0:\n",
    "#     l1_reg = sum(param.abs().sum() for param in self.parameters())\n",
    "#     loss += self.hparams.l1_strength * l1_reg\n",
    "\n",
    "# # L2 regularizer\n",
    "# if l2_hparam > 0:\n",
    "#     l2_reg = sum(param.pow(2).sum() for param in self.parameters())\n",
    "#     loss += self.hparams.l2_strength * l2_reg\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2936e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.linalg import multi_dot\n",
    "\n",
    "def hsic(x, y):\n",
    "    \n",
    "    kx = torch.mm(x, x.T)\n",
    "    ky = torch.mm(y, y.T)\n",
    "    \n",
    "    n = x.shape[0]\n",
    "    ctr_mat = torch.eye(n) - torch.ones((n, n)) / n\n",
    "    \n",
    "    return torch.trace(torch.mm(torch.mm(torch.mm(kx, ctr_mat), ky), ctr_mat)) / (n ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88c49fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = genders.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe5d56d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([470, 7503])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[idx_male[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "081c11f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7384061bd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b17dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_idx = idx_male\n",
    "# test_idx = idx_female\n",
    "train_idx = idx_female\n",
    "test_idx = idx_male\n",
    "n_train = train_idx.shape[0]\n",
    "n_hold = int(0.2 * n_train)\n",
    "n_test = test_idx.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f0bb512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b77ee50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/500], Loss: 4.4146\n",
      "Epoch [20/500], Loss: 3.9380\n",
      "Epoch [30/500], Loss: 2.6179\n",
      "Epoch [40/500], Loss: 1.1742\n",
      "Epoch [50/500], Loss: 0.7223\n",
      "Epoch [60/500], Loss: 0.6666\n",
      "Epoch [70/500], Loss: 0.6982\n",
      "Epoch [80/500], Loss: 0.7414\n",
      "Epoch [90/500], Loss: 0.7505\n",
      "Epoch [100/500], Loss: 0.7323\n",
      "Epoch [110/500], Loss: 0.7145\n",
      "Epoch [120/500], Loss: 0.7069\n",
      "Epoch [130/500], Loss: 0.7049\n",
      "Epoch [140/500], Loss: 0.7031\n",
      "Epoch [150/500], Loss: 0.6999\n",
      "Epoch [160/500], Loss: 0.6966\n",
      "Epoch [170/500], Loss: 0.6941\n",
      "Epoch [180/500], Loss: 0.6923\n",
      "Epoch [190/500], Loss: 0.6907\n",
      "Epoch [200/500], Loss: 0.6893\n",
      "Epoch [210/500], Loss: 0.6880\n",
      "Epoch [220/500], Loss: 0.6869\n",
      "Epoch [230/500], Loss: 0.6860\n",
      "Epoch [240/500], Loss: 0.6852\n",
      "Epoch [250/500], Loss: 0.6845\n",
      "Epoch [260/500], Loss: 0.6839\n",
      "Epoch [270/500], Loss: 0.6833\n",
      "Epoch [280/500], Loss: 0.6829\n",
      "Epoch [290/500], Loss: 0.6825\n",
      "Epoch [300/500], Loss: 0.6821\n",
      "Epoch [310/500], Loss: 0.6818\n",
      "Epoch [320/500], Loss: 0.6815\n",
      "Epoch [330/500], Loss: 0.6813\n",
      "Epoch [340/500], Loss: 0.6811\n",
      "Epoch [350/500], Loss: 0.6809\n",
      "Epoch [360/500], Loss: 0.6807\n",
      "Epoch [370/500], Loss: 0.6805\n",
      "Epoch [380/500], Loss: 0.6804\n",
      "Epoch [390/500], Loss: 0.6802\n",
      "Epoch [400/500], Loss: 0.6801\n",
      "Epoch [410/500], Loss: 0.6799\n",
      "Epoch [420/500], Loss: 0.6798\n",
      "Epoch [430/500], Loss: 0.6796\n",
      "Epoch [440/500], Loss: 0.6795\n",
      "Epoch [450/500], Loss: 0.6793\n",
      "Epoch [460/500], Loss: 0.6791\n",
      "Epoch [470/500], Loss: 0.6789\n",
      "Epoch [480/500], Loss: 0.6786\n",
      "Epoch [490/500], Loss: 0.6783\n",
      "Epoch [500/500], Loss: 0.6780\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = nn.Linear(x.shape[1], 2)\n",
    "\n",
    "# Loss and optimizer\n",
    "# nn.CrossEntropyLoss() computes softmax internally\n",
    "# criterion = F.cross_entropy() \n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.1)  \n",
    "lambda_ = 8.0\n",
    "\n",
    "# Train the model\n",
    "# total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "#     for i, (images, labels) in enumerate(train_loader):\n",
    "#         # Reshape images to (batch_size, input_size)\n",
    "#         images = images.reshape(-1, input_size)\n",
    "        \n",
    "    # Forward pass\n",
    "    y_pred = torch.sigmoid(model(x[train_idx][n_hold:]))\n",
    "#     loss = F.cross_entropy(y_pred, y[idx_male].view(-1)) + nn.MSELoss(model(x)[], genders)\n",
    "#     loss = F.cross_entropy(y_pred, y[idx_male].view(-1)) + F.cross_entropy(torch.sigmoid(model(x)), genders.view(-1))\n",
    "    loss = F.cross_entropy(y_pred, y[train_idx][n_hold:].view(-1)) + lambda_ * (1 - torch.sigmoid(hsic(model(x), genders.float())))\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "# with torch.no_grad():\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for images, labels in test_loader:\n",
    "#         images = images.reshape(-1, input_size)\n",
    "#         outputs = model(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ef99b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4589, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(y_pred, y[train_idx][n_hold:].view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb640565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5701, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsic(model(x), genders.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "721db4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.sigmoid(model(x[train_idx][:n_hold]))\n",
    "_, target = torch.max(pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60ee8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.view((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1619b68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8053)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y[train_idx][:n_hold], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c67124a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pred_f = torch.max(torch.sigmoid(model(x[test_idx])), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b5e328f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6723)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y[test_idx], pred_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2716b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/500], Loss: 0.5544\n",
      "Epoch [20/500], Loss: 0.5187\n",
      "Epoch [30/500], Loss: 0.5266\n",
      "Epoch [40/500], Loss: 0.5339\n",
      "Epoch [50/500], Loss: 0.5342\n",
      "Epoch [60/500], Loss: 0.5333\n",
      "Epoch [70/500], Loss: 0.5332\n",
      "Epoch [80/500], Loss: 0.5333\n",
      "Epoch [90/500], Loss: 0.5332\n",
      "Epoch [100/500], Loss: 0.5332\n",
      "Epoch [110/500], Loss: 0.5332\n",
      "Epoch [120/500], Loss: 0.5332\n",
      "Epoch [130/500], Loss: 0.5332\n",
      "Epoch [140/500], Loss: 0.5332\n",
      "Epoch [150/500], Loss: 0.5332\n",
      "Epoch [160/500], Loss: 0.5332\n",
      "Epoch [170/500], Loss: 0.5332\n",
      "Epoch [180/500], Loss: 0.5332\n",
      "Epoch [190/500], Loss: 0.5332\n",
      "Epoch [200/500], Loss: 0.5332\n",
      "Epoch [210/500], Loss: 0.5332\n",
      "Epoch [220/500], Loss: 0.5332\n",
      "Epoch [230/500], Loss: 0.5332\n",
      "Epoch [240/500], Loss: 0.5332\n",
      "Epoch [250/500], Loss: 0.5332\n",
      "Epoch [260/500], Loss: 0.5332\n",
      "Epoch [270/500], Loss: 0.5332\n",
      "Epoch [280/500], Loss: 0.5332\n",
      "Epoch [290/500], Loss: 0.5332\n",
      "Epoch [300/500], Loss: 0.5332\n",
      "Epoch [310/500], Loss: 0.5332\n",
      "Epoch [320/500], Loss: 0.5332\n",
      "Epoch [330/500], Loss: 0.5332\n",
      "Epoch [340/500], Loss: 0.5332\n",
      "Epoch [350/500], Loss: 0.5332\n",
      "Epoch [360/500], Loss: 0.5332\n",
      "Epoch [370/500], Loss: 0.5332\n",
      "Epoch [380/500], Loss: 0.5332\n",
      "Epoch [390/500], Loss: 0.5332\n",
      "Epoch [400/500], Loss: 0.5332\n",
      "Epoch [410/500], Loss: 0.5332\n",
      "Epoch [420/500], Loss: 0.5332\n",
      "Epoch [430/500], Loss: 0.5332\n",
      "Epoch [440/500], Loss: 0.5332\n",
      "Epoch [450/500], Loss: 0.5332\n",
      "Epoch [460/500], Loss: 0.5332\n",
      "Epoch [470/500], Loss: 0.5332\n",
      "Epoch [480/500], Loss: 0.5332\n",
      "Epoch [490/500], Loss: 0.5332\n",
      "Epoch [500/500], Loss: 0.5332\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "log_reg = nn.Linear(x.shape[1], 2)\n",
    "\n",
    "# Loss and optimizer\n",
    "# nn.CrossEntropyLoss() computes softmax internally\n",
    "# criterion = F.cross_entropy() \n",
    "optimizer = torch.optim.Adam(log_reg.parameters(), lr=learning_rate, weight_decay=1.0)  \n",
    "\n",
    "# Train the model\n",
    "# total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "#     for i, (images, labels) in enumerate(train_loader):\n",
    "#         # Reshape images to (batch_size, input_size)\n",
    "#         images = images.reshape(-1, input_size)\n",
    "        \n",
    "    # Forward pass\n",
    "    y_pred = torch.sigmoid(log_reg(x[train_idx][n_hold:]))\n",
    "    loss = F.cross_entropy(y_pred, y[train_idx][n_hold:].view(-1))\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "# with torch.no_grad():\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for images, labels in test_loader:\n",
    "#         images = images.reshape(-1, input_size)\n",
    "#         outputs = model(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f08c1a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1462e-06, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsic(log_reg(x), genders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddcf9d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0005, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsic(log_reg(x), genders.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dbd4c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_ = torch.sigmoid(log_reg(x[train_idx][:n_hold]))\n",
    "_, pred_lr_f = torch.max(proba_, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33787f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9787)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y[train_idx][:n_hold], pred_lr_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86f0ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_test = torch.sigmoid(log_reg(x[test_idx]))\n",
    "_, pred_lr_test = torch.max(proba_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e143bd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9947)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y[test_idx], pred_lr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ad0d433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02604132, -0.02598074],\n",
       "       [-0.00755683,  0.00788315],\n",
       "       [-0.02889398,  0.02911591],\n",
       "       ...,\n",
       "       [-0.01741947,  0.01761098],\n",
       "       [-0.01815327,  0.01827596],\n",
       "       [-0.01183975,  0.01192712]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight.data.numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfae572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr, _ = pearsonr(model.weight.data.numpy().T[:, 0], log_reg.weight.data.numpy().T[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02f9806d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39115288207116156"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
