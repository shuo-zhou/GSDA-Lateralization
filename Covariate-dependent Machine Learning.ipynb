{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {},
      "source": [
        "## Covariate-dependent learning framework"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torchmetrics.functional import accuracy\n",
        "import os\n",
        "import matplotlib.pylab as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "import io_"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "atlas = 'BNA'\n",
        "# data_dir = 'D:/ShareFolder/BNA/Proc'\n",
        "# out_dir = 'D:/ShareFolder/BNA/Result'\n",
        "data_dir = '/media/shuo/MyDrive/data/HCP/BNA/Proc'\n",
        "out_dir = '/media/shuo/MyDrive/data/HCP/BNA/Results'\n",
        "\n",
        "\n",
        "# atlas = 'AICHA'\n",
        "# data_dir = 'D:/ShareFolder/AICHA_VolFC/Proc'\n",
        "# out_dir = 'D:/ShareFolder/AICHA_VolFC/Result'\n",
        "\n",
        "sessions = ['REST1', 'REST2']  \n",
        "\n",
        "runs = ['RL', 'LR']\n",
        "# connection_type = 'both'  # inter, intra, or both\n",
        "connection_type = 'intra'\n",
        "random_state = 144\n",
        "clf = 'SVC'\n",
        "\n",
        "info = dict()\n",
        "data = dict()\n",
        "\n",
        "session = 'REST1'\n",
        "# run_ = 'LR'\n",
        "run_ = 'Fisherz'\n",
        "# half = 'Left'\n",
        "\n",
        "info_fname = 'HCP_%s_half_brain_%s.csv' % (atlas, session)\n",
        "info[run_] = io_.read_table(os.path.join(data_dir, info_fname), index_col='ID')\n",
        "data[run_] = io_.load_half_brain(data_dir, atlas, session, run_, connection_type)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "from _base import _pick_half\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "x, y, x1, y1 = _pick_half(data[run_])\n",
        "y = label_binarize(y, classes=[1, -1])\n",
        "y1 = label_binarize(y1, classes=[1, -1])\n",
        "# y = y.reshape((-1, 1))\n",
        "genders = info[run_]['gender'].values\n",
        "\n",
        "idx_male = np.where(genders==0)[0]\n",
        "idx_female = np.where(genders==1)[0]\n",
        "\n",
        "\n",
        "x = torch.from_numpy(x)\n",
        "x = x.float()\n",
        "y = torch.from_numpy(y)\n",
        "y = y.long()\n",
        "x1 = torch.from_numpy(x1)\n",
        "x1 = x1.float()\n",
        "y1 = torch.from_numpy(y1)\n",
        "y1 = y1.long()\n",
        "genders = torch.from_numpy(genders.reshape((-1, 1)))\n",
        "genders = genders.float()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "class LR(nn.Module):\n",
        "    def __init__(self, n_features, n_classes, l1_hparam=0.0, l2_hparam=1.0,):\n",
        "        super().__init__()\n",
        "        self.l1_hparam = l1_hparam\n",
        "        self.l2_hparam = l2_hparam\n",
        "        self.linear = nn.Linear(n_features, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        pred = torch.sigmoid(self.linear(x))\n",
        "        return pred\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)  # Generate predictions\n",
        "        pred_loss = F.cross_entropy(out, labels)  # Calculate loss\n",
        "        \n",
        "        # L1 regularizer\n",
        "        if self.l1_hparam > 0:\n",
        "            l1_reg = sum(param.abs().sum() for param in self.parameters())\n",
        "            loss += self.l1_hparam * l1_reg\n",
        "\n",
        "        # L2 regularizer\n",
        "        if self.l2_hparam > 0:\n",
        "            l2_reg = sum(param.pow(2).sum() for param in self.parameters())\n",
        "            loss += self.l2_hparam * l2_reg\n",
        "        \n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)  # Calculate loss\n",
        "        acc = accuracy(out, labels)  # Calculate accuracy\n",
        "        return {'val_loss': loss, 'val_acc': acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()  # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()  # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "l1_hparam = 0.0\n",
        "l2_hparam = 1.0\n",
        "\n",
        "\n",
        "# L1 regularizer\n",
        "# if l1_hparam > 0:\n",
        "#     l1_reg = sum(param.abs().sum() for param in self.parameters())\n",
        "#     loss += self.hparams.l1_strength * l1_reg\n",
        "\n",
        "# # L2 regularizer\n",
        "# if l2_hparam > 0:\n",
        "#     l2_reg = sum(param.pow(2).sum() for param in self.parameters())\n",
        "#     loss += self.hparams.l2_strength * l2_reg\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=1.0)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# from torch.linalg import multi_dot\n",
        "\n",
        "def hsic(x, y):\n",
        "    \n",
        "    kx = torch.mm(x, x.T)\n",
        "    ky = torch.mm(y, y.T)\n",
        "    \n",
        "    n = x.shape[0]\n",
        "    ctr_mat = torch.eye(n) - torch.ones((n, n)) / n\n",
        "    \n",
        "    return torch.trace(torch.mm(torch.mm(torch.mm(kx, ctr_mat), ky), ctr_mat)) / (n ** 2)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "genders = genders.long()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "x[idx_male[0]].shape"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([470, 7503])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "torch.manual_seed(144)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f3d8810fb10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# train_idx = idx_male\n",
        "# test_idx = idx_female\n",
        "train_idx = idx_female\n",
        "test_idx = idx_male\n",
        "n_train = train_idx.shape[0]\n",
        "n_hold = int(0.2 * n_train)\n",
        "n_test = test_idx.shape[0]"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "train_idx.shape[0]"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "563"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "num_epochs = 500\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = nn.Linear(x.shape[1], 2)\n",
        "\n",
        "# Loss and optimizer\n",
        "# nn.CrossEntropyLoss() computes softmax internally\n",
        "# criterion = F.cross_entropy() \n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.1)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.1)  \n",
        "lambda_ = 10\n",
        "\n",
        "# Train the model\n",
        "# total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "#     for i, (images, labels) in enumerate(train_loader):\n",
        "#         # Reshape images to (batch_size, input_size)\n",
        "#         images = images.reshape(-1, input_size)\n",
        "        \n",
        "    # Forward pass\n",
        "    y_pred = torch.sigmoid(model(x[train_idx]))\n",
        "#     loss = F.cross_entropy(y_pred, y[idx_male].view(-1)) + nn.MSELoss(model(x)[], genders)\n",
        "#     loss = F.cross_entropy(y_pred, y[idx_male].view(-1)) + F.cross_entropy(torch.sigmoid(model(x)), genders.view(-1))\n",
        "    loss = F.cross_entropy(y_pred, y[train_idx].view(-1)) + lambda_ * (1 - torch.sigmoid(hsic(model(x), genders.float())))\n",
        "\n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "# with torch.no_grad():\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     for images, labels in test_loader:\n",
        "#         images = images.reshape(-1, input_size)\n",
        "#         outputs = model(images)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum()"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/500], Loss: 5.4378\n",
            "Epoch [20/500], Loss: 5.1447\n",
            "Epoch [30/500], Loss: 3.7529\n",
            "Epoch [40/500], Loss: 1.5556\n",
            "Epoch [50/500], Loss: 0.7453\n",
            "Epoch [60/500], Loss: 0.6428\n",
            "Epoch [70/500], Loss: 0.6584\n",
            "Epoch [80/500], Loss: 0.7055\n",
            "Epoch [90/500], Loss: 0.7375\n",
            "Epoch [100/500], Loss: 0.7334\n",
            "Epoch [110/500], Loss: 0.7141\n",
            "Epoch [120/500], Loss: 0.7002\n",
            "Epoch [130/500], Loss: 0.6947\n",
            "Epoch [140/500], Loss: 0.6931\n",
            "Epoch [150/500], Loss: 0.6912\n",
            "Epoch [160/500], Loss: 0.6883\n",
            "Epoch [170/500], Loss: 0.6852\n",
            "Epoch [180/500], Loss: 0.6827\n",
            "Epoch [190/500], Loss: 0.6808\n",
            "Epoch [200/500], Loss: 0.6791\n",
            "Epoch [210/500], Loss: 0.6775\n",
            "Epoch [220/500], Loss: 0.6761\n",
            "Epoch [230/500], Loss: 0.6747\n",
            "Epoch [240/500], Loss: 0.6735\n",
            "Epoch [250/500], Loss: 0.6724\n",
            "Epoch [260/500], Loss: 0.6714\n",
            "Epoch [270/500], Loss: 0.6704\n",
            "Epoch [280/500], Loss: 0.6694\n",
            "Epoch [290/500], Loss: 0.6685\n",
            "Epoch [300/500], Loss: 0.6676\n",
            "Epoch [310/500], Loss: 0.6667\n",
            "Epoch [320/500], Loss: 0.6659\n",
            "Epoch [330/500], Loss: 0.6650\n",
            "Epoch [340/500], Loss: 0.6642\n",
            "Epoch [350/500], Loss: 0.6633\n",
            "Epoch [360/500], Loss: 0.6624\n",
            "Epoch [370/500], Loss: 0.6616\n",
            "Epoch [380/500], Loss: 0.6607\n",
            "Epoch [390/500], Loss: 0.6598\n",
            "Epoch [400/500], Loss: 0.6589\n",
            "Epoch [410/500], Loss: 0.6580\n",
            "Epoch [420/500], Loss: 0.6571\n",
            "Epoch [430/500], Loss: 0.6562\n",
            "Epoch [440/500], Loss: 0.6553\n",
            "Epoch [450/500], Loss: 0.6544\n",
            "Epoch [460/500], Loss: 0.6534\n",
            "Epoch [470/500], Loss: 0.6525\n",
            "Epoch [480/500], Loss: 0.6516\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "F.cross_entropy(y_pred, y[train_idx].view(-1))"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4619, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "hsic(model(x), genders.float())"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.9234, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "pred = torch.sigmoid(model(x1))\n",
        "_, target = torch.max(pred, 1)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "accuracy(y1[train_idx], target[train_idx])"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8455)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "accuracy(y1[test_idx], target[test_idx])"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6447)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "num_epochs = 500\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "log_reg = nn.Linear(x.shape[1], 2)\n",
        "\n",
        "# Loss and optimizer\n",
        "# nn.CrossEntropyLoss() computes softmax internally\n",
        "# criterion = F.cross_entropy() \n",
        "optimizer = torch.optim.Adam(log_reg.parameters(), lr=learning_rate, weight_decay=1.0)  \n",
        "\n",
        "# Train the model\n",
        "# total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "#     for i, (images, labels) in enumerate(train_loader):\n",
        "#         # Reshape images to (batch_size, input_size)\n",
        "#         images = images.reshape(-1, input_size)\n",
        "        \n",
        "    # Forward pass\n",
        "    y_pred = torch.sigmoid(log_reg(x[train_idx][n_hold:]))\n",
        "    loss = F.cross_entropy(y_pred, y[train_idx][n_hold:].view(-1))\n",
        "\n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "# with torch.no_grad():\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     for images, labels in test_loader:\n",
        "#         images = images.reshape(-1, input_size)\n",
        "#         outputs = model(images)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum()"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/500], Loss: 0.5544\n",
            "Epoch [20/500], Loss: 0.5187\n",
            "Epoch [30/500], Loss: 0.5266\n",
            "Epoch [40/500], Loss: 0.5339\n",
            "Epoch [50/500], Loss: 0.5342\n",
            "Epoch [60/500], Loss: 0.5333\n",
            "Epoch [70/500], Loss: 0.5332\n",
            "Epoch [80/500], Loss: 0.5333\n",
            "Epoch [90/500], Loss: 0.5332\n",
            "Epoch [100/500], Loss: 0.5332\n",
            "Epoch [110/500], Loss: 0.5332\n",
            "Epoch [120/500], Loss: 0.5332\n",
            "Epoch [130/500], Loss: 0.5332\n",
            "Epoch [140/500], Loss: 0.5332\n",
            "Epoch [150/500], Loss: 0.5332\n",
            "Epoch [160/500], Loss: 0.5332\n",
            "Epoch [170/500], Loss: 0.5332\n",
            "Epoch [180/500], Loss: 0.5332\n",
            "Epoch [190/500], Loss: 0.5332\n",
            "Epoch [200/500], Loss: 0.5332\n",
            "Epoch [210/500], Loss: 0.5332\n",
            "Epoch [220/500], Loss: 0.5332\n",
            "Epoch [230/500], Loss: 0.5332\n",
            "Epoch [240/500], Loss: 0.5332\n",
            "Epoch [250/500], Loss: 0.5332\n",
            "Epoch [260/500], Loss: 0.5332\n",
            "Epoch [270/500], Loss: 0.5332\n",
            "Epoch [280/500], Loss: 0.5332\n",
            "Epoch [290/500], Loss: 0.5332\n",
            "Epoch [300/500], Loss: 0.5332\n",
            "Epoch [310/500], Loss: 0.5332\n",
            "Epoch [320/500], Loss: 0.5332\n",
            "Epoch [330/500], Loss: 0.5332\n",
            "Epoch [340/500], Loss: 0.5332\n",
            "Epoch [350/500], Loss: 0.5332\n",
            "Epoch [360/500], Loss: 0.5332\n",
            "Epoch [370/500], Loss: 0.5332\n",
            "Epoch [380/500], Loss: 0.5332\n",
            "Epoch [390/500], Loss: 0.5332\n",
            "Epoch [400/500], Loss: 0.5332\n",
            "Epoch [410/500], Loss: 0.5332\n",
            "Epoch [420/500], Loss: 0.5332\n",
            "Epoch [430/500], Loss: 0.5332\n",
            "Epoch [440/500], Loss: 0.5332\n",
            "Epoch [450/500], Loss: 0.5332\n",
            "Epoch [460/500], Loss: 0.5332\n",
            "Epoch [470/500], Loss: 0.5332\n",
            "Epoch [480/500], Loss: 0.5332\n",
            "Epoch [490/500], Loss: 0.5332\n",
            "Epoch [500/500], Loss: 0.5332\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "hsic(log_reg(x), genders)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.1462e-06, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "hsic(log_reg(x), genders.float())"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0005, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "proba_ = torch.sigmoid(log_reg(x[train_idx][:n_hold]))\n",
        "_, pred_lr_f = torch.max(proba_, 1)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "accuracy(y[train_idx][:n_hold], pred_lr_f)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9787)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "proba_test = torch.sigmoid(log_reg(x[test_idx]))\n",
        "_, pred_lr_test = torch.max(proba_test, 1)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "accuracy(y[test_idx], pred_lr_test)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9947)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "model.weight.data.numpy().T"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.02604132, -0.02598074],\n",
              "       [-0.00755683,  0.00788315],\n",
              "       [-0.02889398,  0.02911591],\n",
              "       ...,\n",
              "       [-0.01741947,  0.01761098],\n",
              "       [-0.01815327,  0.01827596],\n",
              "       [-0.01183975,  0.01192712]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "from scipy.stats import pearsonr\n",
        "corr, _ = pearsonr(model.weight.data.numpy().T[:, 0], log_reg.weight.data.numpy().T[:, 0])"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "corr"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39115288207116156"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "execution_count": null
    }
  ]
}
